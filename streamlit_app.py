import streamlit as st
import google.generativeai as genai
import fitz  # PyMuPDF for PDF parsing

st.title("ğŸ’¬ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé€£æºå‹ Chatbot (Gemini 2.5 Flash æ—¥æœ¬èªå¯¾å¿œ)")

st.write(
    "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€å†…å®¹ã«é–¢ã™ã‚‹è³ªå•ãŒã§ãã¾ã™ã€‚"
    "ã¾ãŸã€è¦ç´„ãƒ»æ ¹æ‹ è¡¨ç¤ºãƒ»ã‚¯ã‚¤ã‚ºæ©Ÿèƒ½ã‚‚åˆ©ç”¨ã§ãã¾ã™ã€‚"
)

api_key = st.secrets.get("GEMINI_API_KEY", "")
if not api_key:
    st.info(
        "ç¶šè¡Œã™ã‚‹ã«ã¯ .streamlit/secrets.toml ã« GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚\n"
        "ä¾‹:\n[GEMINI_API_KEY]\nGEMINI_API_KEY = \"your-api-key\"",
        icon="ğŸ—ï¸"
    )
    st.stop()

genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-1.5-flash")

def extract_text(file):
    if file.name.endswith(".pdf"):
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        return text
    else:
        return file.read().decode("utf-8")

def get_summary_and_highlights(text):
    prompt = f"""
    ä»¥ä¸‹ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã™ã€‚å†…å®¹ã®è¦ç´„ï¼ˆ300æ–‡å­—ä»¥å†…ï¼‰ã¨ã€é‡è¦ãƒã‚¤ãƒ³ãƒˆãƒ»ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼ˆç®‡æ¡æ›¸ãï¼‰ã‚’æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:
    {text}
    """
    response = model.generate_content(prompt)
    return response.candidates[0].content.parts[0].text

def get_answer_and_highlight(text, question):
    prompt = f"""
    ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹ã«åŸºã¥ãã€è³ªå•ã«æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
    ã¾ãŸã€å›ç­”ã®æ ¹æ‹ ã¨ãªã‚‹æ–‡ï¼ˆæœ€å¤§3ã¤ï¼‰ã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æŠœãå‡ºã—ã€Œæ ¹æ‹ ã€ã¨ã—ã¦æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚

    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:
    {text}

    è³ªå•:
    {question}
    """
    response = model.generate_content(prompt)
    answer = response.candidates[0].content.parts[0].text
    return answer

def generate_quiz(text, quiz_type="ç©´åŸ‹ã‚", prev_score=None):
    quiz_prompt = f"""
    ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰{quiz_type}å½¢å¼ã®ã‚¯ã‚¤ã‚ºã‚’1å•ã€æ—¥æœ¬èªã§å‡ºé¡Œã—ã¦ãã ã•ã„ã€‚
    è§£ç­”ãƒ»è§£èª¬ã‚‚ã‚»ãƒƒãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    """
    if prev_score is not None:
        quiz_prompt += f"\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ­£ç­”ç‡ã¯{prev_score*100:.0f}%ã§ã™ã€‚ãŠã™ã™ã‚ã®é–¢é€£ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚‚1ã¤æ¨è–¦ã—ã¦ãã ã•ã„ã€‚"
    quiz_prompt += f"\nãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:\n{text}"
    response = model.generate_content(quiz_prompt)
    return response.candidates[0].content.parts[0].text

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆPDF/TXTï¼‰", type=["pdf", "txt"])
if uploaded_file:
    doc_text = extract_text(uploaded_file)
    st.session_state["doc_text"] = doc_text
    summary_highlights = get_summary_and_highlights(doc_text)
    st.subheader("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¦ç´„ ï¼† ãƒã‚¤ãƒ©ã‚¤ãƒˆ")
    st.markdown(summary_highlights)
else:
    st.info("ã¾ãšãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "user", "content": "ä»Šå¾Œã®è¿”ç­”ã¯ã™ã¹ã¦æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚"}
    ]

if "quiz_score" not in st.session_state:
    st.session_state.quiz_score = []
if "last_quiz" not in st.session_state:
    st.session_state.last_quiz = None

# ã“ã‚Œã¾ã§ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# è³ªå•å…¥åŠ›
with st.expander("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹ã«è³ªå•ã™ã‚‹"):
    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        prompt_with_lang = prompt + "\næ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚"
        st.session_state.messages.append({"role": "user", "content": prompt_with_lang})
        with st.chat_message("user"):
            st.markdown(prompt)

        response_text = get_answer_and_highlight(st.session_state["doc_text"], prompt_with_lang)
        with st.chat_message("assistant"):
            st.markdown(response_text)
        st.session_state.messages.append({"role": "assistant", "content": response_text})

# ã‚¯ã‚¤ã‚ºæ©Ÿèƒ½
with st.expander("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã‚¯ã‚¤ã‚ºã«æŒ‘æˆ¦ï¼"):
    quiz_types = ["ç©´åŸ‹ã‚", "æ­£èª¤å•é¡Œ", "å¿œç”¨å•é¡Œ"]
    selected_quiz = st.selectbox("ã‚¯ã‚¤ã‚ºå½¢å¼ã‚’é¸æŠ", quiz_types)
    if st.button("ã‚¯ã‚¤ã‚ºã‚’å‡ºé¡Œ"):
        prev_score = sum(st.session_state.quiz_score)/max(len(st.session_state.quiz_score),1) if st.session_state.quiz_score else None
        quiz_text = generate_quiz(st.session_state["doc_text"], selected_quiz, prev_score)
        st.session_state.last_quiz = quiz_text
        st.markdown(quiz_text)
    if st.session_state.last_quiz:
        user_answer = st.text_input("ã‚ãªãŸã®ç­”ãˆï¼ˆè‡ªåˆ†ã§ç­”ãˆã¦ã¿ã¦ãã ã•ã„ï¼‰")
        if user_answer and st.button("ç­”ãˆåˆã‚ã›"):
            # Geminiã«æ­£èª¤åˆ¤å®šãƒ»è§£èª¬ã‚’ãŠé¡˜ã„ã™ã‚‹
            check_prompt = f"""
            ä»¥ä¸‹ã¯ã‚¯ã‚¤ã‚ºã®å†…å®¹ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã§ã™ã€‚æ­£èª¤åˆ¤å®šã¨ç°¡å˜ãªè§£èª¬ã‚’æ—¥æœ¬èªã§ã—ã¦ãã ã•ã„ã€‚

            ã‚¯ã‚¤ã‚ºå†…å®¹:
            {st.session_state.last_quiz}

            ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ç­”:
            {user_answer}
            """
            check_response = model.generate_content(check_prompt)
            result = check_response.candidates[0].content.parts[0].text
            st.markdown(result)
            # ç°¡æ˜“:ã€Œæ­£è§£ã€ã€Œä¸æ­£è§£ã€åˆ¤å®šã§ã‚¹ã‚³ã‚¢è¿½åŠ 
            if "æ­£è§£" in result:
                st.session_state.quiz_score.append(1)
            else:
                st.session_state.quiz_score.append(0)
            st.session_state.last_quiz = None
