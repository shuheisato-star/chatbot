import streamlit as st
import google.generativeai as genai
import re

# fitz(Pymupdf)ãŒä½¿ãˆã‚‹ã‹åˆ¤å®š
try:
    import fitz
    SUPPORT_PDF = True
except ImportError:
    SUPPORT_PDF = False

st.title("ğŸ’¬ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé€£æºå‹ Chatbot (Gemini 2.5 Flash æ—¥æœ¬èªå¯¾å¿œ)")

st.write(
    "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€å†…å®¹ã«é–¢ã™ã‚‹è³ªå•ãŒã§ãã¾ã™ã€‚"
    "ã¾ãŸã€è¦ç´„ãƒ»æ ¹æ‹ è¡¨ç¤ºãƒ»ã‚¯ã‚¤ã‚ºï¼ˆé¸æŠå¼æ­£èª¤å•é¡Œï¼‰æ©Ÿèƒ½ã‚‚åˆ©ç”¨ã§ãã¾ã™ã€‚"
)

api_key = st.secrets.get("GEMINI_API_KEY", "")
if not api_key:
    st.info(
        "ç¶šè¡Œã™ã‚‹ã«ã¯ .streamlit/secrets.toml ã« GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚\n"
        "ä¾‹:\n[GEMINI_API_KEY]\nGEMINI_API_KEY = \"your-api-key\"",
        icon="ğŸ—ï¸"
    )
    st.stop()

genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-1.5-flash")

def extract_text(file):
    if SUPPORT_PDF and file.name.endswith(".pdf"):
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        return text
    else:
        return file.read().decode("utf-8")

def get_summary_and_highlights(text):
    prompt = f"""
    ä»¥ä¸‹ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã™ã€‚å†…å®¹ã®è¦ç´„ï¼ˆ300æ–‡å­—ä»¥å†…ï¼‰ã¨ã€é‡è¦ãƒã‚¤ãƒ³ãƒˆãƒ»ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼ˆç®‡æ¡æ›¸ãï¼‰ã‚’æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:
    {text}
    """
    response = model.generate_content(prompt)
    return response.candidates[0].content.parts[0].text

def find_chapter_section(text, answer):
    """
    å›ç­”ã‚„æ ¹æ‹ ã‹ã‚‰ç« ãƒ»ç¯€åã‚’æŠ½å‡ºã™ã‚‹ã€‚
    ä¾‹: ç¬¬3ç« ã€Œå¸‚å ´å‹•å‘ã€ç¬¬5ç¯€ ãªã©
    """
    chapter_pat = r"(ç¬¬[0-9ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ç« [ã€Œã€ã€ã€\w\s]*)"
    section_pat = r"(ç¬¬[0-9ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ç¯€[ã€Œã€ã€ã€\w\s]*)"
    # å›ç­”ã‹ã‚‰æ¢ã™
    chapters = re.findall(chapter_pat, answer)
    sections = re.findall(section_pat, answer)
    # ãªã‘ã‚Œã°å…¨æ–‡ã‹ã‚‰æ¢ã™
    if not chapters:
        chapters = re.findall(chapter_pat, text)
    if not sections:
        sections = re.findall(section_pat, text)
    chapter = chapters[0] if chapters else ""
    section = sections[0] if sections else ""
    if chapter or section:
        return f"{chapter}{(' ' + section) if section else ''}"
    return None

def get_answer_and_highlight_with_source(text, question):
    prompt = f"""
    ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹ã«åŸºã¥ãã€è³ªå•ã«æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
    ã¾ãŸã€å›ç­”ã®æ ¹æ‹ ã¨ãªã‚‹æ–‡ï¼ˆæœ€å¤§3ã¤ï¼‰ã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æŠœãå‡ºã—ã€Œæ ¹æ‹ ã€ã¨ã—ã¦æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚
    ã•ã‚‰ã«ã€æ ¹æ‹ ãŒå­˜åœ¨ã™ã‚‹ç« ãƒ»ç¯€åï¼ˆä¾‹ï¼šç¬¬3ç« ã€Œå¸‚å ´å‹•å‘ã€ç¬¬5ç¯€ï¼‰ã‚’å›ç­”ã®æœ€å¾Œã«ã€Œã“ã®æƒ…å ±ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã€‡ã€‡ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸã‚‚ã®ã§ã™ã€‚ã€ã¨ã„ã†å½¢å¼ã§å¿…ãšè¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚

    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:
    {text}

    è³ªå•:
    {question}
    """
    response = model.generate_content(prompt)
    answer = response.candidates[0].content.parts[0].text

    # å‡ºæ‰€æŠ½å‡ºï¼ˆç« ãƒ»ç¯€ï¼‰
    source_info = find_chapter_section(text, answer)
    if source_info and f"ã“ã®æƒ…å ±ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®" not in answer:
        answer += f"\n\n---\nã“ã®æƒ…å ±ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®{source_info}ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸã‚‚ã®ã§ã™ã€‚"
    elif not source_info and f"ã“ã®æƒ…å ±ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®" not in answer:
        answer += f"\n\n---\nã“ã®æƒ…å ±ã®å‡ºæ‰€ã¯æ˜ç¢ºã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

    return answer, source_info

def visualize_knowledge_flow(question, answer, source_info):
    arrow = "â†’"
    blocks = [
        f"ã€è³ªå•ã€‘\n{question}",
        arrow,
        f"ã€å›ç­”ã€‘\n{answer.split('---')[0].strip()}",
        arrow,
        f"ã€å‡ºæ‰€ã€‘\n{source_info if source_info else 'è©²å½“ç®‡æ‰€ä¸æ˜'}"
    ]
    return "\n\n".join(blocks)

def generate_choice_quiz(text):
    prompt = f"""
    ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã€Œæ­£èª¤å•é¡Œï¼ˆé¸æŠè‚¢ä»˜ãï¼‰ã€ã‚’1å•ã€æ—¥æœ¬èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚
    å¿…ãšä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

    å•é¡Œ: <å•é¡Œæ–‡>
    é¸æŠè‚¢:
    1. <é¸æŠè‚¢1>
    2. <é¸æŠè‚¢2>
    3. <é¸æŠè‚¢3>
    4. <é¸æŠè‚¢4>
    æ­£ç­”ç•ªå·: <æ­£ç­”ã®ç•ªå·>ï¼ˆä¾‹ï¼š2ï¼‰
    è§£èª¬: <è§£èª¬>

    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:
    {text}
    """
    response = model.generate_content(prompt)
    output = response.candidates[0].content.parts[0].text

    # åˆ†å‰²å‡¦ç†
    question, choices, correct_num, explanation = "", [], None, ""
    for line in output.splitlines():
        line = line.strip()
        if line.startswith("å•é¡Œ:"):
            question = line.replace("å•é¡Œ:", "").strip()
        elif line.startswith("é¸æŠè‚¢:"):
            continue
        elif any(line.startswith(f"{i}.") for i in range(1, 10)):
            choices.append(line[line.find(".")+1:].strip())
        elif line.startswith("æ­£ç­”ç•ªå·:"):
            try:
                correct_num = int(line.replace("æ­£ç­”ç•ªå·:", "").strip())
            except ValueError:
                correct_num = None
        elif line.startswith("è§£èª¬:"):
            explanation = line.replace("è§£èª¬:", "").strip()
    return question, choices, correct_num, explanation

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
file_types = ["txt"]
if SUPPORT_PDF:
    file_types.insert(0, "pdf")

uploaded_file = st.file_uploader(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆ{'/'.join(file_types).upper()}ï¼‰", type=file_types)
if uploaded_file:
    doc_text = extract_text(uploaded_file)
    st.session_state["doc_text"] = doc_text
    summary_highlights = get_summary_and_highlights(doc_text)
    st.subheader("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¦ç´„ ï¼† ãƒã‚¤ãƒ©ã‚¤ãƒˆ")
    st.markdown(summary_highlights)
else:
    st.info(f"ã¾ãšãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚å¯¾å¿œå½¢å¼ï¼š{'/'.join(file_types).upper()}")
    st.stop()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãƒ»çŸ¥è­˜ç³»è­œåˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "user", "content": "ä»Šå¾Œã®è¿”ç­”ã¯ã™ã¹ã¦æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚"}
    ]
if "knowledge_flow" not in st.session_state:
    st.session_state.knowledge_flow = []
if "quiz_score" not in st.session_state:
    st.session_state.quiz_score = []
if "last_quiz_data" not in st.session_state:
    st.session_state.last_quiz_data = None
if "last_quiz_selected" not in st.session_state:
    st.session_state.last_quiz_selected = None

# ã“ã‚Œã¾ã§ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# è³ªå•å…¥åŠ›
with st.expander("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹ã«è³ªå•ã™ã‚‹"):
    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        prompt_with_lang = prompt + "\næ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚"
        st.session_state.messages.append({"role": "user", "content": prompt_with_lang})
        with st.chat_message("user"):
            st.markdown(prompt)

        response_text, source_info = get_answer_and_highlight_with_source(st.session_state["doc_text"], prompt_with_lang)
        with st.chat_message("assistant"):
            st.markdown(response_text)
        st.session_state.messages.append({"role": "assistant", "content": response_text})

        # çŸ¥è­˜ã®ã€Œç³»è­œã€å¯è¦–åŒ–
        flow_text = visualize_knowledge_flow(prompt, response_text, source_info)
        st.session_state.knowledge_flow.append(flow_text)
        st.markdown("#### çŸ¥è­˜ã®ã¤ãªãŒã‚Šï¼ˆç³»è­œï¼‰")
        st.markdown(f"<pre style='background:#f8f8ff;border-radius:8px;padding:9px'>{flow_text}</pre>", unsafe_allow_html=True)

# ã€ŒçŸ¥è­˜ã®ç³»è­œã€å±¥æ­´è¡¨ç¤º
if st.session_state.knowledge_flow:
    st.markdown("#### ã“ã‚Œã¾ã§ã®çŸ¥è­˜ã®ç³»è­œå±¥æ­´")
    for flow in st.session_state.knowledge_flow:
        st.markdown(f"<pre style='background:#f8f8ff;border-radius:8px;padding:9px'>{flow}</pre>", unsafe_allow_html=True)

# æ­£èª¤å•é¡Œã‚¯ã‚¤ã‚º
with st.expander("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§æ­£èª¤å•é¡Œã‚¯ã‚¤ã‚ºã«æŒ‘æˆ¦ï¼"):
    if st.button("ã‚¯ã‚¤ã‚ºã‚’å‡ºé¡Œ"):
        question, choices, correct_num, explanation = generate_choice_quiz(st.session_state["doc_text"])
        st.session_state.last_quiz_data = (question, choices, correct_num, explanation)
        st.session_state.last_quiz_selected = None

    if st.session_state.last_quiz_data:
        question, choices, correct_num, explanation = st.session_state.last_quiz_data
        st.markdown(f"**å•é¡Œï¼š** {question}")
        selected_idx = st.selectbox("é¸æŠè‚¢ã‚’é¸ã‚“ã§ãã ã•ã„", options=range(1, len(choices)+1), format_func=lambda x: f"{x}. {choices[x-1]}")
        if st.button("ç­”ãˆåˆã‚ã›"):
            st.session_state.last_quiz_selected = selected_idx

    # å›ç­”å¾Œã®è¡¨ç¤º
    if st.session_state.last_quiz_selected:
        selected_idx = st.session_state.last_quiz_selected
        question, choices, correct_num, explanation = st.session_state.last_quiz_data
        if selected_idx == correct_num:
            st.success(f"æ­£è§£ï¼ ({selected_idx}. {choices[selected_idx-1]})")
            st.session_state.quiz_score.append(1)
        else:
            st.error(f"ä¸æ­£è§£â€¦ æ­£è§£ã¯ {correct_num}. {choices[correct_num-1]} ã§ã™ã€‚")
            st.session_state.quiz_score.append(0)
        st.info(f"è§£èª¬: {explanation}")
        # ã‚¯ã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿æ¶ˆå»
        st.session_state.last_quiz_data = None
        st.session_state.last_quiz_selected = None
